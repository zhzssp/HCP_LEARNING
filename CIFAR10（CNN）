import torch
import torchvision
import torch.nn as nn
from torch.nn import Conv2d, MaxPool2d, Sequential, Flatten, Linear
from tensorboardX import SummaryWriter
from torch.utils.data import DataLoader
from torchvision import transforms
import torch.nn as nn
import time

#下载数据集
train_data = torchvision.datasets.CIFAR10(root="../dataset", train=True, transform=torchvision.transforms.ToTensor(),
                                          download=True)

test_data = torchvision.datasets.CIFAR10(root="../dataset", train=False, transform=torchvision.transforms.ToTensor(),
                                         download=True)
writer = SummaryWriter("../logs")

#查看和保存数据集长度
train_data_size = len(train_data)
test_data_size = len(test_data)
print("训练集长度：{}".format(train_data_size))
print("测试集长度：{}".format(test_data_size))

#加载数据集
train_dataloader = DataLoader(train_data, batch_size=64)
test_dataloader = DataLoader(test_data, batch_size=64)


class Hao(nn.Module):
    def __init__(self):
        super(Hao, self).__init__()
        self.model = Sequential(
            Conv2d(3, 32, 5, 1, 2),
            MaxPool2d(2),
            Conv2d(32, 32, 5, 1, 2),
            MaxPool2d(2),
            Conv2d(32, 64, 5, 1, 2),
            MaxPool2d(2),
            Flatten(),
            Linear(64*4*4, 64),
            Linear(64, 10)
        )

    def forward(self, x):
        x = self.model(x)
        return x
hao = Hao()
# device = torch.device("cuda:0")
# hao = hao.to(device)
hao = hao.cuda()

#loss function
loss_fn = nn.CrossEntropyLoss()
# loss_fn = loss_fn.to(device)
loss_fn = loss_fn.cuda()

#optimizer
learning_rate = 0.01
optimizer = torch.optim.SGD(hao.parameters(), lr=learning_rate)

#设置训练网络的参数
total_train_step = 0
total_test_step = 0
epoch = 1
start_time = time.time()

#训练
for i in range(epoch):
    print("------第{}轮训练开始了------".format(i+1))

    hao.train()
    for data in train_dataloader:
        imgs, tars = data
        # print(imgs)
        # print(tars)
        imgs = imgs.cuda()
        tars = tars.cuda()

        outputs = hao(imgs)
        loss = loss_fn(outputs, tars)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        total_train_step = total_train_step + 1
        if total_train_step % 100 == 0:
            end_time = time.time()
            print(end_time-start_time)
            print("训练次数：{}, loss：{}".format(total_train_step, loss.item()))
            writer.add_scalar("train_loss", loss.item(), total_train_step)

    #测试，将网络设置成测试状态
    hao.eval()
    total_test_loss = 0
    total_right = 0
    with torch.no_grad():
        for data in test_dataloader:
            imgs, tars = data
            imgs = imgs.cuda()
            tars = tars.cuda()
            outputs = hao(imgs)
            # outputs = outputs.cuda()
            loss = loss_fn(outputs, tars)
            total_test_loss = total_test_loss + loss.item()
            right = (outputs.argmax(1) == tars).sum() #特别的判断指标
            total_right += right
    print("测试集整体的loss：{}".format(total_test_loss))
    writer.add_scalar("test_loss", total_test_loss, total_test_step)
    writer.add_scalar("test_accuracy", total_right/test_data_size, total_test_step)
    total_test_step += 1

    torch.save(hao, "hao_{}.pth".format(i+1))
    print("模型已保存")

writer.close()
