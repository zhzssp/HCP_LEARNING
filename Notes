linear regression
1.计算图积累
2.随机数种子

softmax regression
1.累加器Accumulator
2.广播机制

多层感知机
1.收敛定理
2.sigmoid和tanh等涉及到指数运算的激活函数，自动求导的代价较高

模型调优
1.模型容量
2.权重衰退（最广泛的正则化方式），SGD提供该参数选择（1e-3或1e-4为主）
3.丢弃法（数据加入噪音，增强数据鲁棒性），对每个值扰动后的期望值仍为原数（0和xi/(1-p)），只对全连接层使用
4.让梯度在合理范围内，乘法变为加法（ResNet，LSTM），梯度归一化、裁剪，参数初始化，激活函数选取
5.将每一层的输出和梯度都看做随机变量，尽可能使期望和方差保持一致（nγ=1，Xavier初始化，n为输入或输出维度，γ为方差）
6.sigmoid * 4 - 2，调整后在0附近可以有较为稳定的期望和方差sigmoid(x) = x 
7.nan一般是除以0了，inf一般是梯度爆炸了（方差调小，学习率调小）
8.平移不变性（二维卷积/交叉相关），局部性（只在δ范围内设置参数，不关注里ij位置过远的特征），对全连接层使用平移不变性和局部性即得到卷积层

CNN
1.黑白通道为1，彩色通道为3
