linear regression
1.计算图积累
2.随机数种子

softmax regression
1.累加器Accumulator
2.广播机制

多层感知机
1.收敛定理
2.sigmoid和tanh等涉及到指数运算的激活函数，自动求导的代价较高

模型调优
1.模型容量
2.权重衰退（最广泛的正则化方式），SGD提供该参数选择（1e-3或1e-4为主）
3.丢弃法（数据加入噪音，增强数据鲁棒性），对每个值扰动后的期望值仍为原数（0和xi/(1-p)），只对全连接层使用
4.让梯度在合理范围内，乘法变为加法（ResNet，LSTM），梯度归一化、裁剪，合理的参数初始化
5.将每一层的输出和梯度都看做随机变量，尽可能使期望和方差保持一致（nγ=1，Xavier初始化，n为输入或输出维度，γ为方差）
6.sigmoid * 4 - 2，调整后在0附近可以有较为稳定的期望和方差sigmoid(x) = x 
